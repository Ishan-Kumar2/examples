{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "time-profiling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1FzCFk3a1S3"
      },
      "source": [
        "<!-- ---\n",
        "title: How to do time profiling\n",
        "downloads: true\n",
        "sidebar: true\n",
        "tags:\n",
        "  - time-profiling\n",
        "  - BasicTimeProfiler\n",
        "  - Timer\n",
        "  - HandlersTimeProfiler\n",
        "--- -->\n",
        "# How to do time profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J7z60CkssXg"
      },
      "source": [
        "This example demonstrates how you can get the time breakdown for:\n",
        "- All epochs during training\n",
        "- Individual `Events`\n",
        "- All `Handlers` correspoding to an `Event`\n",
        "- Individual `Handlers`\n",
        "- Data loading and Data processing.\n",
        "\n",
        "In this example, we will be using a ResNet18 model on the MNIST dataset. The base code is the same as used in the Getting Started Guide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THcUNAgpWMDF"
      },
      "source": [
        "## Basic Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "Y0sJP9iFa1TB"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor\n",
        "\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from ignite.handlers import Timer\n",
        "from ignite.contrib.handlers import BasicTimeProfiler, HandlersTimeProfiler"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK_9cOP6a1TI"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.model = resnet18(num_classes=10)\n",
        "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    MNIST(download=True, root=\".\", transform=data_transform, train=True),\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    MNIST(download=True, root=\".\", transform=data_transform, train=False),\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUHh-vc73eut"
      },
      "source": [
        "We attach two handlers to the `trainer` to print out the metrics ([`Accuracy`](https://pytorch.org/ignite/generated/ignite.metrics.Accuracy.html#accuracy) and [`Loss`](https://pytorch.org/ignite/generated/ignite.metrics.Loss.html#loss)) of the train and validation dataset at the end of every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItoswUK-23St"
      },
      "source": [
        "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
        "evaluator = create_supervised_evaluator(\n",
        "    model, metrics={\"accuracy\": Accuracy(), \"loss\": Loss(criterion)}, device=device\n",
        ")\n",
        "\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_training_results(trainer):\n",
        "    evaluator.run(train_loader)\n",
        "    metrics = evaluator.state.metrics\n",
        "    print(\n",
        "        f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\"\n",
        "    )\n",
        "\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_validation_results(trainer):\n",
        "    evaluator.run(val_loader)\n",
        "    metrics = evaluator.state.metrics\n",
        "    print(\n",
        "        f\"Validation Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\"\n",
        "    )"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWsePEmAWNmP"
      },
      "source": [
        "## Custom profiling using Timer\n",
        "\n",
        "At the lowest level of abstraction, we provide [`Timer()`](https://pytorch.org/ignite/generated/ignite.handlers.timing.Timer.html#timer) to calculate the time between any set of events. Below, we will calculate the total training time and average time taken by a single epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lccwyNeL4wNW",
        "outputId": "0fad164a-fb7e-4cf4-85cd-36d6712abb25"
      },
      "source": [
        "timer = Timer(average=True)\n",
        "timer.attach(trainer, step=Events.EPOCH_COMPLETED)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ignite.handlers.timing.Timer at 0x7fad40d60e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCCzZr3oH1XM"
      },
      "source": [
        "We set `average=True` to automatically divide the total time the `timer` was running by an internal counter whoose value is decided by the [`step`](https://pytorch.org/ignite/generated/ignite.handlers.timing.Timer.html#ignite.handlers.timing.Timer.step) method. Here we have passed the event `EPOCH_COMPLETED` to `step` so that the internal counter will be incremented every time an epoch is completed. This way `timer.value()` will return `timer.total` divided by the number of epochs which is equal to the average time taken by a single epoch. Finally we attach `timer` to `trainer`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9XSZJu56XOH",
        "outputId": "ddc2244c-f5d2-48f6-94b4-d74648d747dd"
      },
      "source": [
        "trainer.run(train_loader, max_epochs=2)\n",
        "\n",
        "print(\n",
        "    f\"Total time: {timer.total:.2f}, Average time taken by a single epoch: {timer.value():.2f}\"\n",
        ")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch[1] Avg accuracy: 0.97 Avg loss: 0.11\n",
            "Validation Results - Epoch[1] Avg accuracy: 0.97 Avg loss: 0.10\n",
            "Training Results - Epoch[2] Avg accuracy: 0.99 Avg loss: 0.05\n",
            "Validation Results - Epoch[2] Avg accuracy: 0.99 Avg loss: 0.04\n",
            "Total time: 93.11, Average time taken by a single epoch: 46.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTD4UFuZWUSe"
      },
      "source": [
        "## Using `State` of Events\n",
        "\n",
        "If we just want to print the time taken after every epoch and the total time for training we can simply use the `trainer`'s [`State`](https://pytorch.org/ignite/generated/ignite.engine.events.State.html#ignite.engine.events.State). We attach two separate handlers fired when an epoch is completed and when the training is completed to log the time returned by `trainer.state.times`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m1pOALZ3vCO"
      },
      "source": [
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_epoch_time():\n",
        "    print(\n",
        "        f\"Epoch {trainer.state.epoch}, Time Taken : {trainer.state.times['EPOCH_COMPLETED']}\"\n",
        "    )\n",
        "\n",
        "\n",
        "@trainer.on(Events.COMPLETED)\n",
        "def log_total_time():\n",
        "    print(f\"Total Time: {trainer.state.times['COMPLETED']}\")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmdHZIDIABc9",
        "outputId": "eaa53283-3e7f-4cdf-a013-f7fde3baed83"
      },
      "source": [
        "trainer.run(train_loader, max_epochs=2)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch[1] Avg accuracy: 0.99 Avg loss: 0.03\n",
            "Validation Results - Epoch[1] Avg accuracy: 0.99 Avg loss: 0.03\n",
            "Epoch 1, Time Taken : 31.631677865982056\n",
            "Training Results - Epoch[2] Avg accuracy: 0.99 Avg loss: 0.03\n",
            "Validation Results - Epoch[2] Avg accuracy: 0.99 Avg loss: 0.04\n",
            "Epoch 2, Time Taken : 32.099266052246094\n",
            "Total Time: 93.50223469734192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 938\n",
              "\tepoch: 2\n",
              "\tepoch_length: 469\n",
              "\tmax_epochs: 2\n",
              "\toutput: 0.007209857925772667\n",
              "\tbatch: <class 'list'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlT7TUokNIQ7"
      },
      "source": [
        "## Event-based profiling using `BasicTimeProfiler`\n",
        "\n",
        "If we want more information without writing custom code for everything via `Timer()`, we can use [`BasicTimeProfiler()`](https://pytorch.org/ignite/generated/ignite.contrib.handlers.time_profilers.BasicTimeProfiler.html#basictimeprofiler) to get the time taken by data processing, data loading and all pre-defined events."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU37erdra1TK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22ecee8-2187-498c-ea25-122eda12659a"
      },
      "source": [
        "# Attach basic profiler\n",
        "basic_profiler = BasicTimeProfiler()\n",
        "basic_profiler.attach(trainer)\n",
        "\n",
        "trainer.run(train_loader, max_epochs=2)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch[1] Avg accuracy: 0.99 Avg loss: 0.03\n",
            "Validation Results - Epoch[1] Avg accuracy: 0.99 Avg loss: 0.04\n",
            "Epoch 1, Time Taken : 31.97310996055603\n",
            "Training Results - Epoch[2] Avg accuracy: 1.00 Avg loss: 0.01\n",
            "Validation Results - Epoch[2] Avg accuracy: 0.99 Avg loss: 0.03\n",
            "Epoch 2, Time Taken : 32.139504194259644\n",
            "Total Time: 95.06597590446472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 938\n",
              "\tepoch: 2\n",
              "\tepoch_length: 469\n",
              "\tmax_epochs: 2\n",
              "\toutput: 0.11615534871816635\n",
              "\tbatch: <class 'list'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zGDVT4ACJSN"
      },
      "source": [
        "We can then obtain the results dictionary via [`get_results()`](https://pytorch.org/ignite/generated/ignite.contrib.handlers.time_profilers.BasicTimeProfiler.html#ignite.contrib.handlers.time_profilers.BasicTimeProfiler.get_results) and pass it to [`print_results()`](https://pytorch.org/ignite/generated/ignite.contrib.handlers.time_profilers.BasicTimeProfiler.html#ignite.contrib.handlers.time_profilers.BasicTimeProfiler.print_results) to get a nicely formatted output which contains total, minimum, maximum, mean and the standard deviation of the time taken."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "dPxd8R82BfKZ",
        "outputId": "801ce7fe-1a05-4221-f667-0d9c75f46bc8"
      },
      "source": [
        "results = basic_profiler.get_results()\n",
        "basic_profiler.print_results(results)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ----------------------------------------------------\n",
            "| Time profiling stats (in seconds):                 |\n",
            " ----------------------------------------------------\n",
            "total  |  min/index  |  max/index  |  mean  |  std\n",
            "\n",
            "Processing function:\n",
            "47.88717 | 0.04191/468 | 0.05614/469 | 0.05105 | 0.00086\n",
            "\n",
            "Dataflow:\n",
            "16.09671 | 0.01373/467 | 0.03128/694 | 0.01716 | 0.00170\n",
            "\n",
            "Event handlers:\n",
            "30.96817\n",
            "\n",
            "- Events.STARTED: ['Timer.reset']\n",
            "0.00001\n",
            "\n",
            "- Events.EPOCH_STARTED: []\n",
            "0.00001 | 0.00000/1 | 0.00000/0 | 0.00000 | 0.00000\n",
            "\n",
            "- Events.ITERATION_STARTED: []\n",
            "0.00228 | 0.00000/234 | 0.00002/597 | 0.00000 | 0.00000\n",
            "\n",
            "- Events.ITERATION_COMPLETED: []\n",
            "0.00383 | 0.00000/652 | 0.00003/265 | 0.00000 | 0.00000\n",
            "\n",
            "- Events.EPOCH_COMPLETED: ['log_training_results', 'log_validation_results', 'Timer.step', 'log_epoch_time']\n",
            "30.95267 | 14.91956/1 | 16.03311/0 | 15.47634 | 0.78739\n",
            "\n",
            "- Events.COMPLETED: ['Timer.pause', 'log_total_time']\n",
            "0.00004\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n ----------------------------------------------------\\n| Time profiling stats (in seconds):                 |\\n ----------------------------------------------------\\ntotal  |  min/index  |  max/index  |  mean  |  std\\n\\nProcessing function:\\n47.88717 | 0.04191/468 | 0.05614/469 | 0.05105 | 0.00086\\n\\nDataflow:\\n16.09671 | 0.01373/467 | 0.03128/694 | 0.01716 | 0.00170\\n\\nEvent handlers:\\n30.96817\\n\\n- Events.STARTED: ['Timer.reset']\\n0.00001\\n\\n- Events.EPOCH_STARTED: []\\n0.00001 | 0.00000/1 | 0.00000/0 | 0.00000 | 0.00000\\n\\n- Events.ITERATION_STARTED: []\\n0.00228 | 0.00000/234 | 0.00002/597 | 0.00000 | 0.00000\\n\\n- Events.ITERATION_COMPLETED: []\\n0.00383 | 0.00000/652 | 0.00003/265 | 0.00000 | 0.00000\\n\\n- Events.EPOCH_COMPLETED: ['log_training_results', 'log_validation_results', 'Timer.step', 'log_epoch_time']\\n30.95267 | 14.91956/1 | 16.03311/0 | 15.47634 | 0.78739\\n\\n- Events.COMPLETED: ['Timer.pause', 'log_total_time']\\n0.00004\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFzTSk-EChQd"
      },
      "source": [
        "Although this approach does not get the time taken by an individual handler rather the sum of the time taken by all handlers corresponding to a pre-defined event."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orRhb-Z1N8vq"
      },
      "source": [
        "## Handler-based profiling using `HandlersTimeProfiler`\n",
        "\n",
        "We can overcome the above problem by using [`HandlersTimeProfiler`](https://pytorch.org/ignite/generated/ignite.contrib.handlers.time_profilers.HandlersTimeProfiler.html#handlerstimeprofiler) which gives us only the necessary information. We can also calculate the time taken by handlers attached to [`Custom Events`](https://pytorch.org/ignite/concepts.html#custom-events), which was not previously possible, via this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdWobxOs_nuO"
      },
      "source": [
        "# Attach handlers profiler\n",
        "handlers_profiler = HandlersTimeProfiler()\n",
        "handlers_profiler.attach(trainer)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJd487jMBqw2",
        "outputId": "93773c16-81a7-4925-cfb1-799072cec71c"
      },
      "source": [
        "trainer.run(train_loader, max_epochs=2)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Results - Epoch[1] Avg accuracy: 0.99 Avg loss: 0.03\n",
            "Validation Results - Epoch[1] Avg accuracy: 0.99 Avg loss: 0.05\n",
            "Epoch 1, Time Taken : 32.59071087837219\n",
            "Training Results - Epoch[2] Avg accuracy: 1.00 Avg loss: 0.01\n",
            "Validation Results - Epoch[2] Avg accuracy: 0.99 Avg loss: 0.03\n",
            "Epoch 2, Time Taken : 32.15104365348816\n",
            "Total Time: 95.28053855895996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 938\n",
              "\tepoch: 2\n",
              "\tepoch_length: 469\n",
              "\tmax_epochs: 2\n",
              "\toutput: 0.00042030992335639894\n",
              "\tbatch: <class 'list'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_AIlhvqa1TK"
      },
      "source": [
        "We can print the results of the profiler in the same way as above. The output shows total, average and other details of execution time for each handler attached. It also shows the data processing and data loading times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8J8iWyUa1TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca66eae-bbe6-4764-fc2b-3c6c258d136c"
      },
      "source": [
        "results = handlers_profiler.get_results()\n",
        "handlers_profiler.print_results(results)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------  -------------------  --------------  --------------  --------------  --------------  --------------  \n",
            "Handler                                  Event Name                 Total(s)      Min(s)/IDX      Max(s)/IDX         Mean(s)          Std(s)  \n",
            "---------------------------------------  -------------------  --------------  --------------  --------------  --------------  --------------  \n",
            "log_training_results                     EPOCH_COMPLETED            26.26519      12.53628/1      13.72892/0         13.1326         0.84332  \n",
            "log_validation_results                   EPOCH_COMPLETED             4.27147       2.00636/1       2.26511/0         2.13574         0.18296  \n",
            "log_epoch_time                           EPOCH_COMPLETED               7e-05         3e-05/1         4e-05/0           3e-05             0.0  \n",
            "BasicTimeProfiler._as_first_started      STARTED                     0.00071       0.00071/0       0.00071/0         0.00071            None  \n",
            "log_total_time                           COMPLETED                     3e-05         3e-05/0         3e-05/0           3e-05            None  \n",
            "---------------------------------------  -------------------  --------------  --------------  --------------  --------------  --------------  \n",
            "Total                                                               30.53748                                                                  \n",
            "---------------------------------------  -------------------  --------------  --------------  --------------  --------------  --------------  \n",
            "Processing took total 48.09661s [min/index: 0.04275s/937, max/index: 0.05775s/469, mean: 0.05128s, std: 0.00092s]\n",
            "Dataflow took total 16.54468s [min/index: 0.01276s/937, max/index: 0.03142s/281, mean: 0.01764s, std: 0.00205s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0yJpyC7a1TM"
      },
      "source": [
        "The profiling results obtained by `basic_profiler` and `handler_profiler` can be exported to a CSV file by using the `write_results()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6a0t-Xha1TM"
      },
      "source": [
        "basic_profiler.write_results(\"./basic_profile.csv\")\n",
        "handlers_profiler.write_results(\"./handlers_profile.csv\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hG8hYQba1TM"
      },
      "source": [
        "If we inspect the CSV file of `basic_profiler` we can see the depth of information stored for every iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4ZiVInXa1TO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "ac6da60e-ac5d-4ffc-e482-c15036ae0bc7"
      },
      "source": [
        "basic_profile = pd.read_csv(\"./basic_profile.csv\")\n",
        "basic_profile.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>iteration</th>\n",
              "      <th>processing_stats</th>\n",
              "      <th>dataflow_stats</th>\n",
              "      <th>Event_STARTED</th>\n",
              "      <th>Event_COMPLETED</th>\n",
              "      <th>Event_EPOCH_STARTED</th>\n",
              "      <th>Event_EPOCH_COMPLETED</th>\n",
              "      <th>Event_ITERATION_STARTED</th>\n",
              "      <th>Event_ITERATION_COMPLETED</th>\n",
              "      <th>Event_GET_BATCH_STARTED</th>\n",
              "      <th>Event_GET_BATCH_COMPLETED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.056409</td>\n",
              "      <td>0.017553</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>15.994114</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.056446</td>\n",
              "      <td>0.021092</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>15.994114</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.049232</td>\n",
              "      <td>0.017341</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>15.994114</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.051980</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>15.994114</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.050854</td>\n",
              "      <td>0.019154</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>15.994114</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  iteration  ...  Event_GET_BATCH_STARTED  Event_GET_BATCH_COMPLETED\n",
              "0    1.0        1.0  ...                 0.000006                   0.000012\n",
              "1    1.0        2.0  ...                 0.000006                   0.000012\n",
              "2    1.0        3.0  ...                 0.000005                   0.000011\n",
              "3    1.0        4.0  ...                 0.000006                   0.000012\n",
              "4    1.0        5.0  ...                 0.000006                   0.000016\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj06RU9AON93"
      },
      "source": [
        "The `handlers_profile` CSV stores the details for whenever a handler was evoked which corresponds to the number of rows. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "GHCbe28yG0bB",
        "outputId": "4f022ee6-a939-4e6a-dfbe-df738bc285ff"
      },
      "source": [
        "handlers_profile = pd.read_csv(\"./handlers_profile.csv\")\n",
        "handlers_profile.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>processing_stats</th>\n",
              "      <th>dataflow_stats</th>\n",
              "      <th>log_training_results (EPOCH_COMPLETED)</th>\n",
              "      <th>log_validation_results (EPOCH_COMPLETED)</th>\n",
              "      <th>log_epoch_time (EPOCH_COMPLETED)</th>\n",
              "      <th>BasicTimeProfiler._as_first_started (STARTED)</th>\n",
              "      <th>log_total_time (COMPLETED)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.056478</td>\n",
              "      <td>0.030867</td>\n",
              "      <td>13.728917</td>\n",
              "      <td>2.265111</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000714</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.056523</td>\n",
              "      <td>0.017528</td>\n",
              "      <td>12.536277</td>\n",
              "      <td>2.006360</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.049284</td>\n",
              "      <td>0.021065</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.052043</td>\n",
              "      <td>0.017314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.050914</td>\n",
              "      <td>0.016173</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     #  ...  log_total_time (COMPLETED)\n",
              "0  1.0  ...                    0.000029\n",
              "1  2.0  ...                    0.000000\n",
              "2  3.0  ...                    0.000000\n",
              "3  4.0  ...                    0.000000\n",
              "4  5.0  ...                    0.000000\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}